{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "142917ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d9108c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Loughran-McDonald Dictionary\n",
    "lm_dict = pd.read_csv('Loughran-McDonald_MasterDictionary_1993-2023.csv', sep=',', encoding='UTF-8')\n",
    "df_portfolio_1 = pd.read_csv(\"portfolio_articles_1_translated.csv\", sep='|', encoding='UTF-8')\n",
    "df_portfolio_2 = pd.read_csv(\"portfolio_articles_2_translated.csv\", sep='|', encoding='UTF-8')\n",
    "df_portfolio_3 = pd.read_csv(\"portfolio_articles_3_translated.csv\", sep='|', encoding='UTF-8')\n",
    "df = pd.concat([df_portfolio_1, df_portfolio_2,df_portfolio_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab9c9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to a usable format\n",
    "lm_dict['Word'] = lm_dict['Word'].str.lower()\n",
    "positive_words = set(lm_dict[lm_dict['Positive'] != 0]['Word'])\n",
    "negative_words = set(lm_dict[lm_dict['Negative'] != 0]['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25a9bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Step 3: Sentiment Scoring Function\n",
    "def calculate_sentiment(text, pos_words, neg_words):\n",
    "    tokens = preprocess_text(text)\n",
    "    # Count positive and negative words\n",
    "    pos_count = sum(1 for word in tokens if word in pos_words)\n",
    "    neg_count = sum(1 for word in tokens if word in neg_words)\n",
    "    total_words = len(tokens)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    # sentiment score: (pos - neg) / total_words\n",
    "    sentiment_score = (pos_count - neg_count) / total_words\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e8ef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply to DataFrame\n",
    "df['sentiment_score'] = df['translated_content'].apply(\n",
    "    lambda x: calculate_sentiment(x, positive_words, negative_words)\n",
    ")\n",
    "\n",
    "\n",
    "df_final = df.loc[:,['translated_content', 'date', 'sentiment_score']]\n",
    "df_final.to_csv(\"sentiment_scores_LMD_portfolio.csv\", sep=\"|\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6085c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translated_content</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The first Friday of the year ends with an acci...</td>\n",
       "      <td>2025/01/03</td>\n",
       "      <td>-0.104651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The government's decision regarding guest work...</td>\n",
       "      <td>2024/12/24</td>\n",
       "      <td>-0.005076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The speeding is over: Barcelona is cracking do...</td>\n",
       "      <td>2025/01/03</td>\n",
       "      <td>-0.009662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ursula von der Leyen has a serious case of pne...</td>\n",
       "      <td>2025/01/03</td>\n",
       "      <td>-0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unusual weather phenomenon developed at Lake B...</td>\n",
       "      <td>2025/01/03</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15136</th>\n",
       "      <td>The Greeks are getting money. The finance mini...</td>\n",
       "      <td>2018/01/23</td>\n",
       "      <td>-0.041420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15137</th>\n",
       "      <td>Media mogul attacks Facebook and Google. Ameri...</td>\n",
       "      <td>2018/01/23</td>\n",
       "      <td>-0.026087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15138</th>\n",
       "      <td>The US government shutdown has ended, but it c...</td>\n",
       "      <td>2018/01/23</td>\n",
       "      <td>-0.048866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15139</th>\n",
       "      <td>The next installment of the Greek bailout pack...</td>\n",
       "      <td>2018/01/22</td>\n",
       "      <td>-0.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15140</th>\n",
       "      <td>Moody's is worried about the frequent changes ...</td>\n",
       "      <td>2018/01/22</td>\n",
       "      <td>-0.013514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56410 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      translated_content        date  \\\n",
       "0      The first Friday of the year ends with an acci...  2025/01/03   \n",
       "1      The government's decision regarding guest work...  2024/12/24   \n",
       "2      The speeding is over: Barcelona is cracking do...  2025/01/03   \n",
       "3      Ursula von der Leyen has a serious case of pne...  2025/01/03   \n",
       "4      Unusual weather phenomenon developed at Lake B...  2025/01/03   \n",
       "...                                                  ...         ...   \n",
       "15136  The Greeks are getting money. The finance mini...  2018/01/23   \n",
       "15137  Media mogul attacks Facebook and Google. Ameri...  2018/01/23   \n",
       "15138  The US government shutdown has ended, but it c...  2018/01/23   \n",
       "15139  The next installment of the Greek bailout pack...  2018/01/22   \n",
       "15140  Moody's is worried about the frequent changes ...  2018/01/22   \n",
       "\n",
       "       sentiment_score  \n",
       "0            -0.104651  \n",
       "1            -0.005076  \n",
       "2            -0.009662  \n",
       "3            -0.106061  \n",
       "4             0.011494  \n",
       "...                ...  \n",
       "15136        -0.041420  \n",
       "15137        -0.026087  \n",
       "15138        -0.048866  \n",
       "15139        -0.059701  \n",
       "15140        -0.013514  \n",
       "\n",
       "[56410 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e3e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
